{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "# FIT 5202 - Data processing for Big Data\n",
    "\n",
    "## Rain in Australia: Predict rain tomorrow in Australia\n",
    "Predicting rain or weather is a common problem in machine learning. Different machine learning algorithms can be used to model and predict rainfall. In this assignment, we ask you to complete the analysis to predict whether there will be rain tomorrow or not. In particular, you are required to apply the tools of machine learning to visualize and predict the possibility of rainfall in Australia.\n",
    "\n",
    "*Required Datasets (available in Moodle)*:\n",
    "- Rain in Australia **(weatherAUS.csv)**\n",
    "\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf # Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "import matplotlib.pyplot as plt # importing the visualization library\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Creating Spark Session and Loading the Data\n",
    "\n",
    "### Step 01: Import Spark Session and initialize Spark\n",
    "**pyspark** is the Spark Python API that exposes the Spark programming model to Python. You are already familiar with **sparkContext** from Assignment 1. **sparkContext** was used as a channel to access all spark functionality. In order to use APIs of SQL, HIVE, and Streaming, separate contexts need to be created. From SPARK 2.0.0 onwards **sparkSession** provides a single point of entry to interact with underlying Spark functionality and allows programming Spark with Dataframe and Dataset APIs. All the functionality available with **sparkContext** are also available in **sparkSession**. Write the code to create a sparkSession object, with 4 local cores. To create a sparkSession with 4 core you have to use configure it as *local[4]*. Give a name to your program using *appName()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# We will build a configuration \n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Assignment 2\")\n",
    "conf.set(\"spark.master\", \"local[4]\")\n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 02: Load the dataset and print the schema and total number of entries\n",
    "In *sparkSession* you can use *spark_session.read.csv()* method to load data as CSV format. You can download the dataset from Moodle. After you load the csv file into a dataframe using spark session, write the code to print the total number of entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has: 142193 records\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS = spark.read.csv(\"weatherAUS.csv\", header = True)\n",
    "print('The dataframe has:',df_weatherAUS.count(), 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- Evaporation: string (nullable = true)\n",
      " |-- Sunshine: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- Cloud9am: string (nullable = true)\n",
      " |-- Cloud3pm: string (nullable = true)\n",
      " |-- Temp9am: string (nullable = true)\n",
      " |-- Temp3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Data Cleaning and Processing\n",
    "Data cleaning and processing is an important aspect for any machine learning task. We have to carefully look into the data and based on the types, quality of the data, we have to plan our cleaning procedures.\n",
    "\n",
    "### Step 03: Delete columns from the dataset\n",
    "During the data cleaning and processing phase, we delete unnecessary data from the dataset to improve the efficiency and accuracy of our model. You have to think which columns are not contributing to the rain prediction. To keep things simple, you are required to delete the following columns due to data quality and accuracy.\n",
    "- Date\n",
    "- Location\n",
    "- Evaporation\n",
    "- Sunshine\n",
    "- Cloud9am\n",
    "- Cloud3pm\n",
    "- Temp9am\n",
    "- Temp3pm <br>\n",
    "However, if you want to keep any of these columns, you can keep them if you process them in an intelligent way that improve the accuracy, that is fine, **however not mandatory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MinTemp',\n",
       " 'MaxTemp',\n",
       " 'Rainfall',\n",
       " 'WindGustDir',\n",
       " 'WindGustSpeed',\n",
       " 'WindDir9am',\n",
       " 'WindDir3pm',\n",
       " 'WindSpeed9am',\n",
       " 'WindSpeed3pm',\n",
       " 'Humidity9am',\n",
       " 'Humidity3pm',\n",
       " 'Pressure9am',\n",
       " 'Pressure3pm',\n",
       " 'RainToday',\n",
       " 'RainTomorrow']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_clean = df_weatherAUS.drop(*[\"Date\", \"Location\", \"Evaporation\",\n",
    "                                           \"Sunshine\",\"Cloud9am\", \"Cloud3pm\",\"Temp9am\",\"Temp3pm\"])\n",
    "df_weatherAUS_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 04: Print the number of missing data in each column.\n",
    "We already have an initial idea about the data structure from the schema. Even in plain eyes, we can observe that there are lots of NA (null) values in the given dataset. Your job in this step is to print the number of NA(null) values in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Firstly, we will use the method the built-in method <i>isnan</i>, that will return what is being recognized as a null in the dataframe, associated with the count function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|      0|      0|       0|          0|            0|         0|         0|           0|           0|          0|          0|          0|          0|        0|           0|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting nas\n",
    "df_weatherAUS_clean.select([count(when(isnan(c), c)).alias(c) for c in df_weatherAUS_clean.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Since we haven't found any null value, we will count 'NAs', as was asked in the question. Our approach now will be to search for strings that are equal to this characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp : 637\n",
      "MaxTemp : 322\n",
      "Rainfall : 1406\n",
      "WindGustDir : 9330\n",
      "WindGustSpeed : 9270\n",
      "WindDir9am : 10013\n",
      "WindDir3pm : 3778\n",
      "WindSpeed9am : 1348\n",
      "WindSpeed3pm : 2630\n",
      "Humidity9am : 1774\n",
      "Humidity3pm : 3610\n",
      "Pressure9am : 14014\n",
      "Pressure3pm : 13981\n",
      "RainToday : 1406\n",
      "RainTomorrow : 0\n"
     ]
    }
   ],
   "source": [
    "# create a function\n",
    "def countNA(df):\n",
    "    for column in df.columns:  \n",
    "        print(column, \":\", df.filter(df[column] == 'NA').count())\n",
    "\n",
    "countNA(df_weatherAUS_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "With the exception of the column RainTomorrow, all columns have NA's, some more than others. We will proceed assuming this are all null values in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 05: Fill the missing data with average value and maximum occurrence value.\n",
    "In this step you have to fill in all the missing data with average value (for numeric column) or maximum frequency value (for non-numeric column). Firstly, identify the columns which have numeric values (e.g., MinTemp, MaxTemp), calculate the average and fill the null value with the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "As we have seen in step 2 with the printSchema(), all columns are caracterized as string. To identify the columns that numerical and categorical we will print the first row and make the classification by eye. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MinTemp='13.4', MaxTemp='22.9', Rainfall='0.6', WindGustDir='W', WindGustSpeed='44', WindDir9am='W', WindDir3pm='WNW', WindSpeed9am='20', WindSpeed3pm='24', Humidity9am='71', Humidity3pm='22', Pressure9am='1007.7', Pressure3pm='1007.1', RainToday='No', RainTomorrow='No')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first row to identify categorical and numerical values\n",
    "df_weatherAUS_clean.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for numerical and categorical columns \n",
    "numerical_cols = ['MinTemp','MaxTemp','Rainfall','WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "                  'Humidity3pm', 'Pressure9am', 'Pressure3pm']\n",
    "\n",
    "categorical_cols = ['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "To find the average of numerical columns the method <i>describe</i> will be used, as it is particularly to find stats data from dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('summary', 'mean')\n",
      "('MinTemp', '12.186399728729098')\n",
      "('MaxTemp', '23.226784191272444')\n",
      "('Rainfall', '2.3499740743111954')\n",
      "('WindGustSpeed', '39.98429165757619')\n",
      "('WindSpeed9am', '14.001988000994')\n",
      "('WindSpeed3pm', '18.63757586179718')\n",
      "('Humidity9am', '68.8438103105705')\n",
      "('Humidity3pm', '51.482606091656265')\n",
      "('Pressure9am', '1017.6537584159781')\n",
      "('Pressure3pm', '1015.258203537907')\n"
     ]
    }
   ],
   "source": [
    "# Extracting information of mean \n",
    "df_summary = df_weatherAUS_clean.select(numerical_cols).describe().collect()\n",
    "mean_list = df_summary[1] # extracting mean list - the column index 1 has the values of means\n",
    "\n",
    "for item in mean_list.asDict().items():    \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Unfortunately, the same method cannot be used to find the maximum frequency and another approach must be taken. A groupby with count sorted will return the maximum frequency values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WindGustDir : W\n",
      "WindDir9am : N\n",
      "WindDir3pm : SE\n",
      "RainToday : No\n",
      "RainTomorrow : No\n"
     ]
    }
   ],
   "source": [
    "# Extracting information of mode \n",
    "count_list = []\n",
    "for column in categorical_cols:\n",
    "    df = df_weatherAUS_clean.groupBy(column).count()\n",
    "    mode = df.orderBy(df['count'].desc()).collect()[0][0]\n",
    "    count_list.append(mode)\n",
    "    print(column, \":\", mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "In our next step we will make the replacements using the lists that we just generated, `mean_list`and `count_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_cols:\n",
    "    df_weatherAUS_clean = df_weatherAUS_clean.withColumn(column, regexp_replace(column, 'NA', mean_list[column]))\n",
    "\n",
    "support_count = 0    \n",
    "for column in categorical_cols:\n",
    "    df_weatherAUS_clean = df_weatherAUS_clean.withColumn(column, regexp_replace(column, 'NA', count_list[support_count]))\n",
    "    support_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Using the function created in step 4, `countNA`, lets check if the replacement was successful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinTemp : 0\n",
      "MaxTemp : 0\n",
      "Rainfall : 0\n",
      "WindGustDir : 0\n",
      "WindGustSpeed : 0\n",
      "WindDir9am : 0\n",
      "WindDir3pm : 0\n",
      "WindSpeed9am : 0\n",
      "WindSpeed3pm : 0\n",
      "Humidity9am : 0\n",
      "Humidity3pm : 0\n",
      "Pressure9am : 0\n",
      "Pressure3pm : 0\n",
      "RainToday : 0\n",
      "RainTomorrow : 0\n"
     ]
    }
   ],
   "source": [
    "countNA(df_weatherAUS_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 06: Data transformation\n",
    "In this step, you need to transform the data so that it will be useful to process by\n",
    "the machine learning algorithm. Before transforming your non-numerical data, do the\n",
    "type casting (to double) of the numerical value columns as they are defined as “String”\n",
    "(see, the schema of the dataset). For the non-numerical value column (i.e., WindGustDir,\n",
    "WindDir9am, WindDir3pm, RainTomorrow) use the StringIndexer method to convert\n",
    "them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MinTemp: double (nullable = true)\n",
      " |-- MaxTemp: double (nullable = true)\n",
      " |-- Rainfall: double (nullable = true)\n",
      " |-- WindGustSpeed: double (nullable = true)\n",
      " |-- WindSpeed9am: double (nullable = true)\n",
      " |-- WindSpeed3pm: double (nullable = true)\n",
      " |-- Humidity9am: double (nullable = true)\n",
      " |-- Humidity3pm: double (nullable = true)\n",
      " |-- Pressure9am: double (nullable = true)\n",
      " |-- Pressure3pm: double (nullable = true)\n",
      " |-- WindGustDirindex: double (nullable = false)\n",
      " |-- WindDir9amindex: double (nullable = false)\n",
      " |-- WindDir3pmindex: double (nullable = false)\n",
      " |-- RainTodayindex: double (nullable = false)\n",
      " |-- RainTomorrowindex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conversion of column type\n",
    "for column in numerical_cols:\n",
    "    df_weatherAUS_clean = df_weatherAUS_clean.withColumn(column, df_weatherAUS_clean[column].cast('double'))\n",
    "\n",
    "for column in categorical_cols:\n",
    "    l_indexer = StringIndexer(inputCol = column, outputCol = column+\"index\")\n",
    "    df_weatherAUS_clean = l_indexer.fit(df_weatherAUS_clean).transform(df_weatherAUS_clean)\n",
    "    df_weatherAUS_clean = df_weatherAUS_clean.drop(column) # dropping the column \n",
    "    \n",
    "df_weatherAUS_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "The printSchema demonstrates that the task has been successful. We have:\n",
    "- Converted all numerical columns to double\n",
    "- Created indexcolumns type double with numerical values replacing previous strings\n",
    "- Droped previous categorical columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 07: Create the feature vector and divide the dataset\n",
    "In this step, you have to create the feature vector from the given columns. When\n",
    "you create you feature vector, remember to exclude the column that you will be using\n",
    "for testing the accuracy of your model.\n",
    "After creation of your feature vector, you have ​ to split your dataset into two (e.g., training\n",
    "and testing). In this assignment, you have to spit the dataset randomly and between 70\n",
    "percent and 30 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "To create a feature vector we will use the functions `VectorAssembler and vector_assembler.transform`. Once the colum is created and the others are droped the new dataframe will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|RainTomorrowindex|            features|\n",
      "+-----------------+--------------------+\n",
      "|              0.0|[13.4,22.9,0.6,44...|\n",
      "|              0.0|[7.4,25.1,0.0,44....|\n",
      "|              0.0|[12.9,25.7,0.0,46...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=[\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindGustSpeed\",\"WindSpeed9am\",\n",
    "                \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\",\"Pressure3pm\",\n",
    "               \"WindGustDirindex\", \"WindDir9amindex\",\"WindDir3pmindex\", \"RainTodayindex\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "\n",
    "df_weatherAUS_clean = vector_assembler.transform(df_weatherAUS_clean)\n",
    "\n",
    "# Drop all unwanted columns \n",
    "cols_list = [\"features\", \"RainTomorrowindex\"]\n",
    "df_weatherAUS_clean = df_weatherAUS_clean.select([cols for cols in df_weatherAUS_clean.columns if cols in cols_list])\n",
    "\n",
    "df_weatherAUS_clean.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Great, now we will split the data in train and test using `randomSplit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = df_weatherAUS_clean.randomSplit([0.7, 0.3], seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Apply Machine Learning Algorithms\n",
    "**Step 08: Apply machine learning classification algorithms on the dataset and\n",
    "compare their accuracy. Plot the accuracy as bar graph.**<br>\n",
    "You have to use ​ DecisionTreeClassifier(), RandomForestClassifier(), and\n",
    "LogisticRegression(), GBTClassifier() methods in spark to calculate the probability of the\n",
    "rain fall tomorrow based on the other related data points (e.g., temperature, wind,\n",
    "humidity). Finally, you have to draw the graph (e.g. bar chart) to demonstrate the\n",
    "comparison of their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Create a evaluator `MulticlassClassificationEvaluator` to calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrowindex\", \n",
    "                                              predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Now we will apply similar methods to create models as asked. A new dataframe will be genareted from the trainning data for each classifier and accuracy will be calculated in sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|RainTomorrowindex|\n",
      "+----------+-----------------+\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.164488 \n",
      "Accuracy 0.8355119056030523\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"RainTomorrowindex\", featuresCol=\"features\", seed = 1000)\n",
    "\n",
    "dt_model = dt.fit(trainingData)\n",
    "\n",
    "dt_predictions = dt_model.transform(testData)\n",
    "\n",
    "dt_predictions.select(\"prediction\", \"RainTomorrowindex\").show(5)\n",
    "\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "\n",
    "print(\"Test Error = %g \" % (1.0 - dt_accuracy))\n",
    "print(\"Accuracy\", dt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|RainTomorrowindex|\n",
      "+----------+-----------------+\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.164135\n",
      "Accuracy 0.8358651875927365\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"RainTomorrowindex\", featuresCol=\"features\", numTrees=10, seed = 1000)\n",
    "rf_model = rf.fit(trainingData)\n",
    "\n",
    "rf_predictions = rf_model.transform(testData)\n",
    "\n",
    "rf_predictions.select(\"prediction\", \"RainTomorrowindex\").show(5)\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - rf_accuracy))\n",
    "print(\"Accuracy\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|RainTomorrowindex|\n",
      "+----------+-----------------+\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.183801\n",
      "Accuracy 0.8161991568336513\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'RainTomorrowindex', maxIter=10)\n",
    "lr_model = lr.fit(trainingData)\n",
    "\n",
    "lr_predictions = lr_model.transform(testData)\n",
    "\n",
    "lr_predictions.select(\"prediction\", \"RainTomorrowindex\").show(5)\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - lr_accuracy))\n",
    "print(\"Accuracy\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|RainTomorrowindex|\n",
      "+----------+-----------------+\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "|       0.0|              0.0|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.158765\n",
      "Accuracy 0.8412350738359359\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(featuresCol = 'features', labelCol = 'RainTomorrowindex', maxIter=10, seed = 1000)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "\n",
    "gbt_predictions = gbt_model.transform(testData)\n",
    "\n",
    "gbt_predictions.select(\"prediction\", \"RainTomorrowindex\").show(5)\n",
    "\n",
    "gbt_accuracy = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - gbt_accuracy))\n",
    "print(\"Accuracy\", gbt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Plotting the Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "model = [lr_accuracy, dt_accuracy, rf_accuracy, gbt_accuracy]\n",
    "bars = ( 'Logistic Regression', 'Decision Tree', 'Random Forest', 'GBT')\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "plt.title('Comparative Chart of ML models Accuracy', fontsize = 17)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('ML Model')\n",
    "plt.ylim(0.81, 0.85)\n",
    "plt.grid(linestyle='-', linewidth='0.5', color='grey')\n",
    "\n",
    "plt.bar(y_pos, model, color=['black', 'red', 'green', 'blue'])\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "We can observe in the plot that the GBT model had the best accuracy, followed by Random forest, Decision Tree and finally Logistic Regression. Nevertheless, all accuracies are quite similar, in a range between 0.81 and 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 09: Calculate the confusion matrix and find the precision, recall, and F1\n",
    "score of each classification algorithm. Explain how the accuracy of the\n",
    "predication can be improved?**<br>\n",
    "    Finding the accuracy of the model does not always represent the quality of the\n",
    "model for a given dataset. Number of false positive and false negative identification also\n",
    "plays an important role when we decide about any particular classification model. The\n",
    "way we can calculate is called confusion matrix. You can use confusionMatrix() method\n",
    "to calculate the confusion matrix. From the confusion matrix show the precision, recall\n",
    "and f1 score of each classification model. Explain how you can improve the accuracy of\n",
    "the ​ prediction​ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printstats(RDD):\n",
    "    \n",
    "    metrics = MulticlassMetrics(RDD)\n",
    "    Confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    print(\"Confusion Matrix\\n\")\n",
    "    print(Confusion_matrix)    \n",
    "    print('\\n')\n",
    "    print('True Positives:',  Confusion_matrix[1][1])\n",
    "    print('False Positives:', Confusion_matrix[0][1])\n",
    "    print('False Negatives:', Confusion_matrix[1][0])\n",
    "    print('True Negatives:',  Confusion_matrix[0][0])\n",
    "    print('\\n')\n",
    "\n",
    "    precision = Confusion_matrix[1][1]/(Confusion_matrix[1][1] + Confusion_matrix[0][1])   \n",
    "    recall = Confusion_matrix[1][1]/(Confusion_matrix[1][1] + Confusion_matrix[1][0])    \n",
    "    F1 = 2*precision*recall/(precision+recall)\n",
    "    \n",
    "    print('Precision:', precision)    \n",
    "    print('Recall:', recall)\n",
    "    print('F1:',  F1)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Evaluation of Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[31850.  1117.]\n",
      " [ 5867.  3625.]]\n",
      "\n",
      "\n",
      "True Positives: 3625.0\n",
      "False Positives: 1117.0\n",
      "False Negatives: 5867.0\n",
      "True Negatives: 31850.0\n",
      "\n",
      "\n",
      "Precision: 0.7644453816954871\n",
      "Recall: 0.38190054782975136\n",
      "F1: 0.5093438246452157\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_pred_RDD = dt_predictions.select(\"prediction\", \"RainTomorrowindex\").rdd.map(lambda line: (line[0], line[1]))\n",
    "printstats(dt_pred_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Evaluation of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[31802.  1165.]\n",
      " [ 5804.  3688.]]\n",
      "\n",
      "\n",
      "True Positives: 3688.0\n",
      "False Positives: 1165.0\n",
      "False Negatives: 5804.0\n",
      "True Negatives: 31802.0\n",
      "\n",
      "\n",
      "Precision: 0.7599423037296518\n",
      "Recall: 0.3885377159713443\n",
      "F1: 0.514186127570582\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pred_RDD = rf_predictions.select(\"prediction\", \"RainTomorrowindex\").rdd.map(lambda line: (line[0], line[1]))\n",
    "printstats(rf_pred_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "\n",
    "Evaluation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[30616.  2351.]\n",
      " [ 5453.  4039.]]\n",
      "\n",
      "\n",
      "True Positives: 4039.0\n",
      "False Positives: 2351.0\n",
      "False Negatives: 5453.0\n",
      "True Negatives: 30616.0\n",
      "\n",
      "\n",
      "Precision: 0.6320813771517997\n",
      "Recall: 0.42551622418879054\n",
      "F1: 0.5086261176174286\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred_RDD = lr_predictions.select(\"prediction\", \"RainTomorrowindex\").rdd.map(lambda line: (line[0], line[1]))\n",
    "printstats(lr_pred_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Evaluation of GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[31474.  1493.]\n",
      " [ 5248.  4244.]]\n",
      "\n",
      "\n",
      "True Positives: 4244.0\n",
      "False Positives: 1493.0\n",
      "False Negatives: 5248.0\n",
      "True Negatives: 31474.0\n",
      "\n",
      "\n",
      "Precision: 0.739759456161757\n",
      "Recall: 0.4471133586177834\n",
      "F1: 0.5573576728609889\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBT_pred_RDD = gbt_predictions.select(\"prediction\", \"RainTomorrowindex\").rdd.map(lambda line: (line[0], line[1]))\n",
    "printstats(GBT_pred_RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\"><b>\n",
    "Improving model accuracy: To improve the accuracy of machine learning models there are many possible approaches, altough none of then are guarateed to work. \n",
    "\n",
    "- Firstly, if possible, adding more data will much likely contribute to a better model accuracy. \n",
    "- We could investigate if there was a better approach to handle missing data. For instance, to replace missing categorical missing values, a multinomial logistic regression, or a K Nearest Neighbors regression could be tried. In respect to numerical values, a simple regression would possibly be better than replacing by the mean. Also, may be they are not \"missing at random\", which means there is a specific reason the data is missing, and once it is found it possibile to make a better rule for replacement than the one that were used.  \n",
    "- Investigating and eliminating outliers is also a possibility, as they may generate bias to the model.\n",
    "- Feature selection, and I would like to point out this as the most relevant at this point. As we can see in this [link](https://datascienceplus.com/weather-forecast-with-regression-models-part-1/), some of the columns shouldn't have been excluded, specially `Cloud9am` and`Cloud3pm`. This conclusion came from the fact that this variables have different distributions on days before rain and before sunny days, which indicates they can have a good predictive power.\n",
    "- Finally another option would be to algorithm Tuning, which mean work on the hyperparameters of the models and try to improve the accuracy. For instance, in a random forest a key parameter is the number of trees, so we should raise the number of trees significantly, but with care, otherwise we can start overfitting the model and accuracy will decrease. With respects to Decision Trees, increasing the parameter max_depth also can be used to improve accuracy, specially when there are many features and complex data (but with concerns to overffiting). Gradient boost trees can be improved by Tree-Specific Parameters, they affect each individual tree in the model, Boosting Parameters, that affect the boosting operation in the model and Miscellaneous Parameters, other parameters for overall functioning. Increasing the parameter min_samples_leaf, for instance, would be a fear try to increase accuracy, as there are many feautures being modelled. In respect to logistic Regression the best parameter to target is 'maxiter'.<br><br><br><br>\n",
    "\n",
    "References:<br>\n",
    "https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4 <br>\n",
    "https://www.analyticsvidhya.com/blog/2015/12/improve-machine-learning-results/ <br>\n",
    "https://datascienceplus.com/weather-forecast-with-regression-models-part-1/ <br>\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
