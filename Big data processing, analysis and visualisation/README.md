# Big Data Processing, Analysis and Visualisation


## Description

   1) `Analysing Text Data.ipynb`

Analysis of two books on software development methodologies (txt files). We will see the distribution of words, the most common words in both books and the average frequency.

The steps consist of: importing `pyspark` and initializing Spark, creating Resilient Distributed Datasets (RDDs), cleaning/manipulating text, transforming the cata/counting the words, removing Stop Words, finding the average occurrence of a word and exploratory data analysis.


   2) `Analysing CSV Data.ipynb`

   Analysis of crime data from South Australia.

   Here we work with `MongoDB` and Spark DataFrames.

## Data
- `Agile Processes in Software Engineering and Extreme Programming.txt`: Book1
- `Scrum Handbook.txt`: Book2
- `Crime_Statistics_SA_2010_present.csv`: The dataset reflects reported incidents of crime (suburb-based crime statistics for crimes against the person and crimes against property.) that occurred in South Australia since 2010.


## Visuals - Data Exploration

**Part A - Analysis of words from the books.**

![Imgur](https://i.imgur.com/7ElwzBg.png)

**part B - Analysis of Crimes by day of the week.**

![Imgur](https://i.imgur.com/ZNO8b79.png)


